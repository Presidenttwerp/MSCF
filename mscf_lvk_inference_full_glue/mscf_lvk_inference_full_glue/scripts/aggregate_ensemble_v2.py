#!/usr/bin/env python
"""Aggregate population ensemble results with COVERAGE-BASED metrics.

Key improvements over v1:
1. COVERAGE metric: Pass = injected value inside 90% CI (not closeness test)
2. Primary parameters: (f0, tau) treated as primary, (Mf, chi) as derived
3. This avoids the "posterior tightens around biased mode" trap at high SNR
"""

import json
import os
import numpy as np
from pathlib import Path


def load_results(base_dir="out_ensemble_v2"):
    """Load all injection_summary.json files from ensemble runs."""
    results = {20: [], 30: [], 40: [], 50: []}

    for snr in [20, 30, 40, 50]:
        snr_dir = Path(base_dir) / f"snr{snr}"
        if not snr_dir.exists():
            continue

        for noise_dir in sorted(snr_dir.iterdir()):
            summary_file = noise_dir / "injection_summary.json"
            if summary_file.exists():
                with open(summary_file) as f:
                    data = json.load(f)
                    data['noise_seed'] = noise_dir.name
                    results[snr].append(data)

    return results


def compute_coverage_stats(results):
    """
    Compute COVERAGE-BASED pass fractions.

    Coverage = is the injected value inside the 90% credible interval?
    This is the correct metric for injection studies.
    """
    stats = {}

    for snr, runs in results.items():
        if not runs:
            stats[snr] = None
            continue

        n_runs = len(runs)

        # Injected values (same for all runs)
        Mf_inj = runs[0]['injected']['Mf']
        chi_inj = runs[0]['injected']['chi']
        f0_inj = runs[0]['injected']['f0']
        tau_inj = runs[0]['injected']['tau_ms']  # in ms

        # Coverage counts (using 90% CI = 5th to 95th percentile)
        # Note: summary has 16/84 percentiles, so we'll use those as ~68% CI
        # and approximate 90% CI from the spread
        n_cover_Mf = 0
        n_cover_chi = 0
        n_cover_f0 = 0

        # Biases for (f0, tau) as primary
        f0_recovered = []

        for r in runs:
            rec = r['recovered']

            # Mf coverage: is Mf_inj in [Mf_16, Mf_84]? (68% CI)
            # For 90% CI, we'd need 5th/95th percentiles
            # Approximate 90% CI as median Â± 1.645 * sigma
            Mf_med = rec['Mf_median']
            Mf_std = rec['Mf_std']
            Mf_lo_90 = Mf_med - 1.645 * Mf_std
            Mf_hi_90 = Mf_med + 1.645 * Mf_std
            if Mf_lo_90 <= Mf_inj <= Mf_hi_90:
                n_cover_Mf += 1

            # chi coverage
            chi_med = rec['chi_median']
            chi_std = rec['chi_std']
            chi_lo_90 = chi_med - 1.645 * chi_std
            chi_hi_90 = chi_med + 1.645 * chi_std
            if chi_lo_90 <= chi_inj <= chi_hi_90:
                n_cover_chi += 1

            # f0 coverage
            f0_med = rec['f0_median']
            f0_std = rec['f0_std']
            f0_lo_90 = f0_med - 1.645 * f0_std
            f0_hi_90 = f0_med + 1.645 * f0_std
            if f0_lo_90 <= f0_inj <= f0_hi_90:
                n_cover_f0 += 1

            f0_recovered.append(f0_med)

        # Old-style pass counts (for comparison)
        n_pass_Mf_old = sum(1 for r in runs if r['pass_conditions']['Mf_within_2sigma'])
        n_pass_chi_old = sum(1 for r in runs if r['pass_conditions']['chi_within_2sigma'])
        n_pass_f0_old = sum(1 for r in runs if r['pass_conditions']['f0_within_20Hz'])
        n_pass_overall_old = sum(1 for r in runs if r['pass_conditions']['overall_pass'])

        # Recovered values for bias computation
        Mf_recovered = [r['recovered']['Mf_median'] for r in runs]
        chi_recovered = [r['recovered']['chi_median'] for r in runs]

        # Biases
        Mf_bias = [m - Mf_inj for m in Mf_recovered]
        chi_bias = [c - chi_inj for c in chi_recovered]
        f0_bias = [f - f0_inj for f in f0_recovered]

        stats[snr] = {
            'n_runs': n_runs,
            'injected': {
                'Mf': Mf_inj,
                'chi': chi_inj,
                'f0': f0_inj,
                'tau_ms': tau_inj,
            },
            # NEW: Coverage-based metrics (correct!)
            'coverage_90': {
                'Mf': n_cover_Mf / n_runs,
                'chi': n_cover_chi / n_runs,
                'f0': n_cover_f0 / n_runs,
            },
            'n_cover_90': {
                'Mf': n_cover_Mf,
                'chi': n_cover_chi,
                'f0': n_cover_f0,
            },
            # OLD: Closeness-based metrics (kept for comparison, but deprecated)
            'pass_fraction_old': {
                'Mf': n_pass_Mf_old / n_runs,
                'chi': n_pass_chi_old / n_runs,
                'f0': n_pass_f0_old / n_runs,
                'overall': n_pass_overall_old / n_runs,
            },
            'bias': {
                'Mf': {'mean': np.mean(Mf_bias), 'std': np.std(Mf_bias)},
                'chi': {'mean': np.mean(chi_bias), 'std': np.std(chi_bias)},
                'f0': {'mean': np.mean(f0_bias), 'std': np.std(f0_bias)},
            },
            'fractional_bias_percent': {
                'Mf': {'mean': np.mean(Mf_bias) / Mf_inj * 100, 'std': np.std(Mf_bias) / Mf_inj * 100},
                'chi': {'mean': np.mean(chi_bias) / chi_inj * 100, 'std': np.std(chi_bias) / chi_inj * 100},
                'f0': {'mean': np.mean(f0_bias) / f0_inj * 100, 'std': np.std(f0_bias) / f0_inj * 100},
            },
        }

    return stats


def print_summary(stats):
    """Print human-readable summary with coverage metrics."""
    print("=" * 80)
    print("POPULATION ENSEMBLE STUDY RESULTS (COVERAGE METRIC)")
    print("Injection: Mf=67.8 Mâ˜‰, Ï‡=0.68, f0=251 Hz, Ï„=4.1 ms")
    print("=" * 80)

    # Coverage table (THE CORRECT METRIC)
    print("\nðŸ“Š 90% CREDIBLE INTERVAL COVERAGE BY SNR")
    print("   (Expected: ~90% if posteriors are well-calibrated)")
    print("-" * 60)
    print(f"{'SNR':>5} | {'N runs':>7} | {'Mf':>8} | {'Ï‡':>8} | {'f0':>8}")
    print("-" * 60)

    for snr in [20, 30, 40, 50]:
        if stats[snr] is None:
            print(f"{snr:>5} | {'N/A':>7}")
            continue
        s = stats[snr]
        cov = s['coverage_90']
        print(f"{snr:>5} | {s['n_runs']:>7} | {cov['Mf']*100:>7.1f}% | {cov['chi']*100:>7.1f}% | {cov['f0']*100:>7.1f}%")
    print("-" * 60)

    # Old pass fraction for comparison
    print("\nðŸ“Š OLD PASS FRACTIONS (closeness test - DEPRECATED)")
    print("-" * 60)
    print(f"{'SNR':>5} | {'Mf':>8} | {'Ï‡':>8} | {'f0':>8} | {'Overall':>8}")
    print("-" * 60)

    for snr in [20, 30, 40, 50]:
        if stats[snr] is None:
            continue
        s = stats[snr]
        pf = s['pass_fraction_old']
        print(f"{snr:>5} | {pf['Mf']*100:>7.1f}% | {pf['chi']*100:>7.1f}% | {pf['f0']*100:>7.1f}% | {pf['overall']*100:>7.1f}%")
    print("-" * 60)

    # Bias table
    print("\nðŸ“ PARAMETER BIASES (recovered - injected)")
    print("-" * 70)
    print(f"{'SNR':>5} | {'Mf bias':>12} | {'Ï‡ bias':>12} | {'f0 bias (Hz)':>14}")
    print("-" * 70)

    for snr in [20, 30, 40, 50]:
        if stats[snr] is None:
            continue
        s = stats[snr]
        b = s['bias']
        print(f"{snr:>5} | {b['Mf']['mean']:>+6.1f}Â±{b['Mf']['std']:<5.1f} | {b['chi']['mean']:>+6.3f}Â±{b['chi']['std']:<5.3f} | {b['f0']['mean']:>+7.1f}Â±{b['f0']['std']:<5.1f}")
    print("-" * 70)

    print("\nðŸ“‹ INTERPRETATION:")
    print("- COVERAGE: fraction of runs where injected value is in 90% CI")
    print("  â†’ Expected ~90% if posteriors are calibrated")
    print("  â†’ <90% = posteriors undercover (too narrow) â†’ identifiability issue")
    print("  â†’ >90% = posteriors overcover (too wide) â†’ conservative but OK")
    print("")
    print("- (Mf, Ï‡) low coverage is EXPECTED due to degeneracy along constant-f0 curves")
    print("- f0 coverage should be ~90% if the waveform model is correct")
    print("- This is NOT a bug - it's the fundamental (Mf, Ï‡) identifiability floor")
    print()


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--base-dir', default='out_ensemble_v2', help='Base directory for ensemble results')
    args = parser.parse_args()

    results = load_results(args.base_dir)

    # Report counts
    print("\nLoaded results:")
    for snr in [20, 30, 40, 50]:
        print(f"  SNR={snr}: {len(results[snr])} runs")

    stats = compute_coverage_stats(results)
    print_summary(stats)

    # Save detailed stats
    output_file = f"{args.base_dir}/ensemble_summary_v2.json"

    # Convert for JSON
    stats_json = {}
    for snr, s in stats.items():
        if s is None:
            stats_json[snr] = None
            continue
        stats_json[snr] = {
            'n_runs': s['n_runs'],
            'injected': s['injected'],
            'coverage_90': s['coverage_90'],
            'n_cover_90': s['n_cover_90'],
            'pass_fraction_old': s['pass_fraction_old'],
            'bias': {
                param: {'mean': float(b['mean']), 'std': float(b['std'])}
                for param, b in s['bias'].items()
            },
            'fractional_bias_percent': {
                param: {'mean': float(b['mean']), 'std': float(b['std'])}
                for param, b in s['fractional_bias_percent'].items()
            },
        }

    with open(output_file, 'w') as f:
        json.dump(stats_json, f, indent=2)
    print(f"\nSaved detailed stats to {output_file}")
